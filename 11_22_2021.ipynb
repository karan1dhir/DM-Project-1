{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBof534sM2hL",
    "outputId": "27238607-8247-49b2-ff53-9544e3c5dd42"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/', force_remount=True)\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Co89tT0AM2hM"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Reshape, Dropout, BatchNormalization, Convolution2D, Activation, MaxPooling2D, Flatten, AveragePooling2D, Input, GaussianNoise\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from skimage.transform import resize\n",
    "from numpy import rollaxis\n",
    "from IPython.display import FileLink\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy import ndimage\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# !pip install zip_files\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Kxe2uKS7la7"
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train_2.npz\")[\"arr_0\"]\n",
    "y_train = np.load(\"y_train_2.npz\")[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w-hHEzqQTf5c"
   },
   "outputs": [],
   "source": [
    "# # from google.colab.patches import cv2_imshow\n",
    "\n",
    "# for i in range(x_train.shape[0]):\n",
    "#     if random.randint(0,15) < 5:\n",
    "#         print(i)\n",
    "        \n",
    "#         rand_num = random.randint(0,3)\n",
    "#         if rand_num == 0:\n",
    "#             next_image = x_train[i,:,:,:]\n",
    "#             next_label = y_train[i,:,:]\n",
    "\n",
    "#             zeros = np.zeros((244,244,3))\n",
    "#             shift = random.randint(60,100)\n",
    "#               # print(x_shift)\n",
    "#               # print(zeros[x_shift:,:,:].shape)\n",
    "#               # print(next_image[:next_image.shape[0] - x_shift,:,:].shape)\n",
    "#             zeros[shift:,:,:] = next_image[:next_image.shape[0] - shift,:,:]\n",
    "#             next_label[:,1] += shift\n",
    "            \n",
    "#         elif rand_num == 1:\n",
    "#             next_image = x_train[i,:,:,:]\n",
    "#             next_label = y_train[i,:,:]\n",
    "\n",
    "#             zeros = np.zeros((244,244,3))\n",
    "#             shift = random.randint(-100,-60)\n",
    "#               # print(x_shift)\n",
    "#               # print(zeros[x_shift:,:,:].shape)\n",
    "#               # print(next_image[:next_image.shape[0] - x_shift,:,:].shape)\n",
    "#             zeros[:shift,:,:] = next_image[-shift:,:,:]\n",
    "#             next_label[:,1] += shift\n",
    "\n",
    "#         elif rand_num == 2:\n",
    "#             next_image = x_train[i,:,:,:]\n",
    "#             next_label = y_train[i,:,:]\n",
    "\n",
    "#             zeros = np.zeros((244,244,3))\n",
    "#             shift = random.randint(60,100)\n",
    "#               # print(x_shift)\n",
    "#               # print(zeros[x_shift:,:,:].shape)\n",
    "#               # print(next_image[:next_image.shape[0] - x_shift,:,:].shape)\n",
    "#             zeros[:,shift:,:] = next_image[:,:next_image.shape[1] - shift,:]\n",
    "#             next_label[:,0] += shift\n",
    "            \n",
    "#         elif rand_num == 3:\n",
    "#             next_image = x_train[i,:,:,:]\n",
    "#             next_label = y_train[i,:,:]\n",
    "\n",
    "#             zeros = np.zeros((244,244,3))\n",
    "#             shift = random.randint(-100,-60)\n",
    "#               # print(x_shift)\n",
    "#               # print(zeros[x_shift:,:,:].shape)\n",
    "#               # print(next_image[:next_image.shape[0] - x_shift,:,:].shape)\n",
    "#             zeros[:,:shift,:] = next_image[:,-shift:,:]\n",
    "#             next_label[:,0] += shift\n",
    "        \n",
    "        \n",
    "# #         print(zeros.shape)\n",
    "# #         for point in next_label:\n",
    "# #             zeros = cv2.circle(zeros, tuple([int(x) for x in point[:2]]), radius=3, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "# #         cv2.imshow(\"window\",zeros*255)\n",
    "        \n",
    "\n",
    "#         zeros = np.reshape(zeros, (1, 244, 244, 3))\n",
    "#         next_label = np.reshape(next_label, (1, 68, 3))\n",
    "\n",
    "#         x_train = np.vstack((x_train, zeros))\n",
    "#         y_train = np.vstack((y_train, next_label))\n",
    "    \n",
    "# #     print(next_label)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "czY7njIEkkaw"
   },
   "outputs": [],
   "source": [
    "# np.savez(\"x_train_2.npz\", x_train)\n",
    "# np.savez(\"y_train_2.npz\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtqRQBeirHhD"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YX33fbUHq3YN"
   },
   "outputs": [],
   "source": [
    "# output_dims = 68*3\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "# ### Model architecture modified from https://towardsdatascience.com/detecting-facial-features-using-deep-learning-2e23c8660a7a\n",
    "\n",
    "# IMG_SHAPE = (244,244,3)\n",
    "# base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False, \n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#   base_model,\n",
    "#   Convolution2D(256, 5, strides=(3,3), activation=\"relu\"),\n",
    "#   MaxPooling2D(),\n",
    "#   # Convolution2D(128, 5, strides=(3,3), activation=\"relu\"),\n",
    "#   # MaxPooling2D(),\n",
    "#   # Convolution2D(128, 3, strides=(3,3), activation=\"relu\"),\n",
    "#   # Convolution2D(128, 3, strides=(1,1), activation=\"relu\"),\n",
    "#   Flatten(),\n",
    "#   Dense(2048, activation=\"relu\"),\n",
    "#   Dense(204, activation=\"relu\"),\n",
    "#   Reshape((68, 3))\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "\n",
    "# # x,y=augment_data(x_train, y_train)\n",
    "    \n",
    "    \n",
    "# #     np.savez_compressed(\"x_train.npz\",x_train)\n",
    "# #     np.savez_compressed(\"y_train.npz\",y_train)\n",
    "\n",
    "# filepath = f\"/content/drive/MyDrive/facial_model_{time.time()}.h5\"\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# # model = load_model(filepath)\n",
    "\n",
    "# model.fit(\n",
    "#         x=x,\n",
    "#         y=y/244,\n",
    "#         epochs=200000,\n",
    "#         verbose=1,\n",
    "#         shuffle=True,\n",
    "#         steps_per_epoch=16,\n",
    "#         batch_size=16,\n",
    "#         validation_data=(x_test,y_test/244),\n",
    "#         callbacks=callbacks_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GboozqHo6ZLq"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "filepath = f\"/content/drive/MyDrive/facial_model_{time.time()}.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "gray_train = np.dot(x_train[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "input_img = tf.keras.Input(shape=(244, 244, 1))\n",
    "\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(input_img)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.UpSampling2D((2, 2))(encoded)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"valid\")(x)\n",
    "\n",
    "autoencoder = tf.keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adagrad', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I4hAX3Cd_bWT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 244, 244, 1)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 244, 244, 1)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 244, 244, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 244, 244, 256)     2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 122, 122, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 128)     295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 256, 256, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 1)       2305      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 252, 252, 1)       10        \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 250, 250, 1)       10        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 248, 248, 1)       10        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 246, 246, 1)       10        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 244, 244, 1)       10        \n",
      "=================================================================\n",
      "Total params: 788,979\n",
      "Trainable params: 788,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lfFAbz5N-DSU"
   },
   "outputs": [],
   "source": [
    "# autoencoder.fit(\n",
    "#         x=gray_train,\n",
    "#         y=gray_train,\n",
    "#         epochs=200000,\n",
    "#         verbose=1,\n",
    "#         shuffle=True,\n",
    "#         steps_per_epoch=16,\n",
    "#         batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4ui1-b-CWpAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "backbone = tf.keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(244,244,3)\n",
    ")\n",
    "\n",
    "backbone.trainable = False\n",
    "\n",
    "inputs = layers.Input((244,244,3))\n",
    "x_ = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x_ = backbone(x_)\n",
    "x_ = layers.Dropout(0.3)(x_)\n",
    "x_ = layers.BatchNormalization()(x_)\n",
    "x_ = layers.SeparableConv2D(\n",
    "    204, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.BatchNormalization()(x_)\n",
    "x_ = layers.SeparableConv2D(\n",
    "    204, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.BatchNormalization()(x_)\n",
    "x_ = layers.SeparableConv2D(\n",
    "    204, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.Dropout(0.3)(x_)\n",
    "\n",
    "x_ = layers.Flatten()(x_)\n",
    "\n",
    "x_ = layers.Dense(204, activation=\"sigmoid\")(x_)\n",
    "outputs = layers.Reshape((68,3))(x_)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xoiwnVynujBK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 244, 244, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambd (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLamb (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 8, 8, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 1280)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 1280)        5120      \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 6, 6, 204)         272844    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 6, 204)         816       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 4, 4, 204)         43656     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 204)         816       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 2, 2, 204)         43656     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 204)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 816)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 204)               166668    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 68, 3)             0         \n",
      "=================================================================\n",
      "Total params: 2,791,560\n",
      "Trainable params: 530,200\n",
      "Non-trainable params: 2,261,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bwewpYZ-tW96"
   },
   "outputs": [],
   "source": [
    "# filepath = f\"facial_model_{time.time()}.h5\"\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='mean_absolute_error', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# model.compile(loss=\"mean_absolute_error\", optimizer=\"rmsprop\")\n",
    "# model.fit(x_train, y_train / 244, epochs=100000, batch_size=32, steps_per_epoch=16, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NaLyoQOiuDh2"
   },
   "outputs": [],
   "source": [
    "# filepath = f\"facial_model_{time.time()}.h5\"\n",
    "# model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eOJxu-UU3ByO"
   },
   "outputs": [],
   "source": [
    "# filepath = f\"facial_model_{time.time()}.h5\"\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='mean_absolute_error', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# model.compile(loss=\"mean_absolute_error\", optimizer=\"adagrad\")\n",
    "# model.fit(x_train, y_train / 244, epochs=100000, batch_size=32, steps_per_epoch=16, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = f\"facial_model_{time.time()}.h5\"\n",
    "# model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = f\"facial_model_{time.time()}.h5\"\n",
    "\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='mean_absolute_percentage_error', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# model.compile(loss=\"mean_absolute_percentage_error\", optimizer=\"adagrad\")\n",
    "# model.fit(x_train, y_train / 244, epochs=100000, batch_size=32, steps_per_epoch=16, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4632, 244, 244, 3)\n",
      "(5790, 244, 244, 3)\n",
      "(4632, 68, 3)\n",
      "(5790, 68, 3)\n"
     ]
    }
   ],
   "source": [
    "x, x_test, y, y_test = train_test_split(x_train, y_train, test_size=.20)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(y.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# backbone = tf.keras.applications.MobileNetV2(\n",
    "#     weights=\"imagenet\", include_top=False, input_shape=(244,244,3)\n",
    "# )\n",
    "\n",
    "# backbone.trainable = False\n",
    "\n",
    "inputs = layers.Input((244,244,3))\n",
    "x_ = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "# x_ = backbone(x_)\n",
    "# x_ = layers.Dropout(0.3)(x_)\n",
    "# x_ = layers.BatchNormalization()(x_)\n",
    "x_ = layers.Conv2D(204, kernel_size=3, strides=1, activation=\"relu\")(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    32, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.Conv2D(\n",
    "    32, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.Conv2D(\n",
    "    64, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.Conv2D(\n",
    "    64, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.Conv2D(\n",
    "    204, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.Conv2D(\n",
    "    204, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "\n",
    "x_ = layers.Dropout(0.3)(x_)\n",
    "\n",
    "x_ = layers.Flatten()(x_)\n",
    "\n",
    "x_ = layers.Dense(204, activation=\"sigmoid\")(x_)\n",
    "outputs = layers.Reshape((68,3))(x_)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 244, 244, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_4 (TFOpLambd (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_4 (TFOpLamb (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 242, 242, 204)     5712      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 240, 240, 32)      58784     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 118, 118, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 57, 57, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 11, 11, 204)       117708    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 5, 204)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 3, 3, 204)         374748    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 204)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1836)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 204)               374748    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 68, 3)             0         \n",
      "=================================================================\n",
      "Total params: 996,372\n",
      "Trainable params: 996,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "1024/1024 [==============================] - 154s 145ms/step - loss: 94.0498 - val_loss: 99.9943\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 99.99435, saving model to facial_model_1637806965.7487626.h5\n",
      "Epoch 2/100000\n",
      " 127/1024 [==>...........................] - ETA: 2:09 - loss: 140.4763"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10172/3311005314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_absolute_percentage_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m244\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m244\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \"\"\"\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath = f\"facial_model_{time.time()}.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=\"adam\")\n",
    "model.fit(x, y / 244, epochs=100000, batch_size=16, steps_per_epoch=1024, callbacks=callbacks_list, validation_data=(x_test, y_test / 244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"facial_model_{time.time()}.h5\"\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# backbone = tf.keras.applications.MobileNetV2(\n",
    "#     weights=\"imagenet\", include_top=False, input_shape=(244,244,3)\n",
    "# )\n",
    "\n",
    "# backbone.trainable = False\n",
    "\n",
    "inputs = layers.Input((244,244,3))\n",
    "x_ = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x_ = layers.Conv2D(204, kernel_size=3, strides=1, activation=\"relu\")(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    64, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    32, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    32, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    16, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "x_ = layers.Conv2D(\n",
    "    16, kernel_size=3, strides=1, activation=\"relu\"\n",
    ")(x_)\n",
    "x_ = layers.MaxPooling2D()(x_)\n",
    "\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "x_ = layers.TransposeConv2D(16, 3, 1, activation=\"relu\")(x_)\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "x_ = layers.TransposeConv2D(16, 3, 1, activation=\"relu\")(x_)\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "x_ = layers.TransposeConv2D(32, 3, 1, activation=\"relu\")(x_)\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "x_ = layers.TransposeConv2D(32, 3, 1, activation=\"relu\")(x_)\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "x_ = layers.TransposeConv2D(64, 3, 1, activation=\"relu\")(x_)\n",
    "x_ = layers.UpSampling2D()(x_)\n",
    "outputs = layers.TransposeConv2D(204, 3, 1, activation=\"relu\")(x_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs, outputs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "11-22-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
